{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation With GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aG7hg6VhOHDa",
        "BB-s8yyoimb8",
        "yoZoymBVisFj",
        "d6ekzolAT2Sc"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvTj7YUigJlR"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGEsDa9zgLcO"
      },
      "source": [
        "For the text generation of each celebrity with the GPT-2 model, the procedure is the same. \n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Select all the texts belonging to the celebrity in question and turn it into one corpus.\n",
        "\n",
        "2. Use that corpus to train the GPT-2 model.\n",
        "\n",
        "3. After training the model, create some sample text for the celebrity.\n",
        "\n",
        "4. Export the generated text using pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OdIs8XaPLfs",
        "outputId": "5357104a-1659-4b7f-8738-e570fc6c3065"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  print('File not in drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKCnzuJWSU7j"
      },
      "source": [
        "# import libraries\n",
        "import pickle\n",
        "import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "I2mWwkhaQR7-",
        "outputId": "02c07c10-ecde-45b4-916d-4888c38de8d6"
      },
      "source": [
        "# import preprocessed dataset\n",
        "pickle_in = open('df.pickle', 'rb')\n",
        "df = pickle.load(pickle_in)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9eba6da52c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdAREHllG9y2"
      },
      "source": [
        " df[df['Username']=='daniel tosh']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O1VG4TgSlzi"
      },
      "source": [
        "## Installing GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inL3lDBNSfZ7",
        "outputId": "05dc525d-fd05-418a-8008-01992da3e8e2"
      },
      "source": [
        "!pip install -q gpt_2_simple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jq3JqW7T-hU",
        "outputId": "f521b7e1-37e1-48b4-f7ce-93171a305f43"
      },
      "source": [
        "!pip install tensorflow==1.14\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.19.5)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (54.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoEWH6bsSu3I"
      },
      "source": [
        "# import tensorflow and gpt-2 libraries\n",
        "import tensorflow as tf\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofdk2jBJUekQ"
      },
      "source": [
        "# show names of celebrities\n",
        "names = sorted(list(df['Username'].value_counts().index))\n",
        "print(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLt2309yUpPx"
      },
      "source": [
        "# return text corpus for a given data frame\n",
        "def corpus(df):\n",
        "  corpus = \"\"\n",
        "  for text in df['Text (Model)']:\n",
        "    corpus = corpus + str(text)\n",
        "  return corpus\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa5p7WB9TMlQ"
      },
      "source": [
        "# select the small version of the GPT-2 model and download it\n",
        "model_name = '124M'\n",
        "gpt2.download_gpt2(model_name=model_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG7hg6VhOHDa"
      },
      "source": [
        "## Alicia Keys Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB-s8yyoimb8"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8H1_zqYVoZ8",
        "outputId": "72c873d0-5623-4e09-a3a7-a54aca3c9e2b"
      },
      "source": [
        "# select the needed corpus and train the model with it\n",
        "keys = df[df['Username']== \"Alicia Keys\"]\n",
        "keys_corpus = corpus(keys)\n",
        "\n",
        "text_file = open(\"Alicia Keys.txt\", \"w\")\n",
        "n = text_file.write(keys_corpus)\n",
        "text_file.close()\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess, \n",
        "              'Alicia Keys.txt',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 20436 tokens\n",
            "Training...\n",
            "[1 | 118.60] loss=4.41 avg=4.41\n",
            "[2 | 234.91] loss=4.22 avg=4.32\n",
            "[3 | 349.94] loss=4.30 avg=4.31\n",
            "[4 | 460.78] loss=3.90 avg=4.21\n",
            "[5 | 571.35] loss=4.02 avg=4.17\n",
            "[6 | 681.51] loss=3.96 avg=4.13\n",
            "[7 | 792.64] loss=3.67 avg=4.06\n",
            "[8 | 912.72] loss=3.81 avg=4.03\n",
            "[9 | 1024.17] loss=3.88 avg=4.01\n",
            "[10 | 1135.84] loss=3.87 avg=4.00\n",
            "[11 | 1248.15] loss=3.82 avg=3.98\n",
            "[12 | 1361.11] loss=3.70 avg=3.96\n",
            "[13 | 1480.05] loss=3.73 avg=3.94\n",
            "[14 | 1592.57] loss=3.58 avg=3.91\n",
            "[15 | 1704.56] loss=3.39 avg=3.87\n",
            "[16 | 1818.22] loss=3.38 avg=3.84\n",
            "[17 | 1930.64] loss=3.03 avg=3.79\n",
            "[18 | 2043.35] loss=3.37 avg=3.76\n",
            "[19 | 2159.25] loss=3.37 avg=3.74\n",
            "[20 | 2271.51] loss=3.04 avg=3.70\n",
            "[21 | 2383.04] loss=2.99 avg=3.66\n",
            "[22 | 2495.09] loss=3.21 avg=3.64\n",
            "[23 | 2607.00] loss=2.96 avg=3.61\n",
            "[24 | 2723.77] loss=3.15 avg=3.59\n",
            "[25 | 2836.27] loss=2.79 avg=3.55\n",
            "[26 | 2948.26] loss=2.73 avg=3.52\n",
            "[27 | 3060.76] loss=2.81 avg=3.49\n",
            "[28 | 3173.32] loss=2.72 avg=3.46\n",
            "[29 | 3292.07] loss=2.68 avg=3.42\n",
            "[30 | 3409.70] loss=2.40 avg=3.39\n",
            "[31 | 3522.33] loss=2.49 avg=3.35\n",
            "[32 | 3634.30] loss=2.21 avg=3.31\n",
            "[33 | 3746.77] loss=2.51 avg=3.28\n",
            "[34 | 3858.89] loss=2.34 avg=3.25\n",
            "[35 | 3983.51] loss=2.16 avg=3.21\n",
            "[36 | 4096.03] loss=2.30 avg=3.18\n",
            "[37 | 4208.45] loss=2.21 avg=3.15\n",
            "[38 | 4320.96] loss=2.38 avg=3.13\n",
            "[39 | 4433.59] loss=2.28 avg=3.10\n",
            "[40 | 4548.94] loss=1.88 avg=3.06\n",
            "[41 | 4661.96] loss=1.90 avg=3.03\n",
            "[42 | 4774.38] loss=1.84 avg=2.99\n",
            "[43 | 4886.75] loss=1.89 avg=2.96\n",
            "[44 | 4998.91] loss=1.74 avg=2.93\n",
            "[45 | 5110.83] loss=1.92 avg=2.90\n",
            "[46 | 5222.82] loss=1.49 avg=2.86\n",
            "[47 | 5334.73] loss=1.59 avg=2.83\n",
            "[48 | 5447.48] loss=1.52 avg=2.80\n",
            "[49 | 5559.94] loss=1.49 avg=2.76\n",
            "[50 | 5672.39] loss=1.46 avg=2.73\n",
            "[51 | 5784.92] loss=1.30 avg=2.69\n",
            "[52 | 5898.52] loss=1.23 avg=2.66\n",
            "[53 | 6011.77] loss=1.33 avg=2.62\n",
            "[54 | 6124.70] loss=1.18 avg=2.59\n",
            "[55 | 6238.31] loss=1.12 avg=2.56\n",
            "[56 | 6351.18] loss=0.85 avg=2.52\n",
            "[57 | 6464.55] loss=0.67 avg=2.47\n",
            "[58 | 6577.77] loss=0.94 avg=2.44\n",
            "[59 | 6690.60] loss=0.84 avg=2.40\n",
            "[60 | 6803.63] loss=1.04 avg=2.37\n",
            "[61 | 6916.01] loss=0.94 avg=2.34\n",
            "[62 | 7028.59] loss=0.80 avg=2.31\n",
            "[63 | 7140.77] loss=0.84 avg=2.28\n",
            "[64 | 7253.04] loss=0.69 avg=2.24\n",
            "[65 | 7365.59] loss=0.80 avg=2.21\n",
            "[66 | 7478.22] loss=0.70 avg=2.18\n",
            "[67 | 7590.94] loss=0.59 avg=2.15\n",
            "[68 | 7703.71] loss=0.54 avg=2.12\n",
            "[69 | 7816.42] loss=0.54 avg=2.09\n",
            "[70 | 7928.61] loss=0.37 avg=2.05\n",
            "[71 | 8040.90] loss=0.38 avg=2.02\n",
            "[72 | 8153.19] loss=0.42 avg=1.99\n",
            "[73 | 8266.22] loss=0.32 avg=1.96\n",
            "[74 | 8378.74] loss=0.37 avg=1.93\n",
            "[75 | 8491.37] loss=0.31 avg=1.90\n",
            "[76 | 8603.87] loss=0.42 avg=1.87\n",
            "[77 | 8725.29] loss=0.42 avg=1.84\n",
            "[78 | 8837.83] loss=0.36 avg=1.81\n",
            "[79 | 8950.07] loss=0.31 avg=1.79\n",
            "[80 | 9062.47] loss=0.31 avg=1.76\n",
            "[81 | 9175.72] loss=0.26 avg=1.73\n",
            "[82 | 9293.59] loss=0.23 avg=1.71\n",
            "[83 | 9405.93] loss=0.27 avg=1.68\n",
            "[84 | 9518.12] loss=0.19 avg=1.65\n",
            "[85 | 9630.14] loss=0.22 avg=1.63\n",
            "[86 | 9743.11] loss=0.23 avg=1.60\n",
            "[87 | 9856.20] loss=0.26 avg=1.58\n",
            "[88 | 9969.57] loss=0.13 avg=1.56\n",
            "[89 | 10083.09] loss=0.25 avg=1.54\n",
            "[90 | 10195.85] loss=0.21 avg=1.51\n",
            "[91 | 10309.38] loss=0.15 avg=1.49\n",
            "[92 | 10422.50] loss=0.17 avg=1.47\n",
            "[93 | 10535.15] loss=0.17 avg=1.45\n",
            "[94 | 10647.65] loss=0.20 avg=1.43\n",
            "[95 | 10760.41] loss=0.12 avg=1.41\n",
            "[96 | 10873.62] loss=0.12 avg=1.38\n",
            "[97 | 10987.92] loss=0.14 avg=1.36\n",
            "[98 | 11100.52] loss=0.12 avg=1.34\n",
            "[99 | 11212.88] loss=0.08 avg=1.32\n",
            "[100 | 11325.21] loss=0.11 avg=1.31\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoZoymBVisFj"
      },
      "source": [
        "### Generating Text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqEXbwnzWuyc"
      },
      "source": [
        "# generate text with the model\n",
        "keys_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pqih-3meWmL"
      },
      "source": [
        "# export generated text\n",
        "keys_pickle_out = open('keys_text_generation.pickle', 'wb')\n",
        "pickle.dump(keys_text_generation, keys_pickle_out)\n",
        "keys_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmo-XixtlzDH"
      },
      "source": [
        "## Anthony Joshua Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF7oV7edmG6N"
      },
      "source": [
        "# select text corpus\n",
        "joshua = df[df['Username']== 'Anthony Joshua']\n",
        "joshua_corpus = corpus(joshua)\n",
        "\n",
        "text_file = open(\"Anthony Joshua.txt\", \"w\")\n",
        "n = text_file.write(joshua_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2R46sI2l5a7"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7wPOQaAmr5E",
        "outputId": "d39b1eef-ea07-4186-e86d-da39fda26139"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              'Anthony Joshua.txt',\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 207.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 11552 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1161.76] loss=3.49 avg=3.49\n",
            "[20 | 2318.51] loss=3.04 avg=3.26\n",
            "[30 | 3481.07] loss=1.86 avg=2.79\n",
            "[40 | 4626.67] loss=1.22 avg=2.39\n",
            "[50 | 5782.56] loss=0.72 avg=2.05\n",
            "[60 | 6947.20] loss=0.25 avg=1.74\n",
            "[70 | 8104.79] loss=0.10 avg=1.50\n",
            "[80 | 9263.24] loss=0.23 avg=1.34\n",
            "[90 | 10432.25] loss=0.10 avg=1.19\n",
            "[100 | 11607.40] loss=0.04 avg=1.07\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRuT_UKSmCX4"
      },
      "source": [
        "### Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy9AoS7vl4vt"
      },
      "source": [
        "# generate text\n",
        "joshua_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmIHsLC8gwQQ"
      },
      "source": [
        "# export generated text\n",
        "joshua_pickle_out = open('joshua_text_generation.pickle', 'wb')\n",
        "pickle.dump(joshua_text_generation, joshua_pickle_out)\n",
        "joshua_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZc2bnOZhAJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_KQlv9DhDJ6"
      },
      "source": [
        "## Barack Obama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuTGdHRthHv3"
      },
      "source": [
        "# select text corpus\n",
        "obama = df[df['Username']== 'Barack Obama']\n",
        "obama_corpus = corpus(obama)\n",
        "\n",
        "text_file = open(\"Barack Obama.txt\", \"w\")\n",
        "n = text_file.write(obama_corpus)\n",
        "text_file.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PPb0IY8hRDY",
        "outputId": "f5fbab45-d58a-4269-b3ae-a9697cfd1e06"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              'Barack Obama.txt',\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 33389 tokens\n",
            "Training...\n",
            "[10 | 1234.54] loss=3.06 avg=3.06\n",
            "[20 | 2481.22] loss=2.12 avg=2.59\n",
            "[30 | 3746.23] loss=2.45 avg=2.54\n",
            "[40 | 5002.97] loss=2.03 avg=2.41\n",
            "[50 | 6245.99] loss=1.49 avg=2.23\n",
            "[60 | 7493.48] loss=1.07 avg=2.03\n",
            "[70 | 8736.15] loss=1.17 avg=1.90\n",
            "[80 | 9977.23] loss=0.63 avg=1.74\n",
            "[90 | 11241.61] loss=0.69 avg=1.62\n",
            "[100 | 12509.88] loss=0.25 avg=1.47\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pBGT9mohf1z"
      },
      "source": [
        " # generate text\n",
        " obama_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY7jCUrAlQ7x"
      },
      "source": [
        "# export generated text\n",
        "obama_pickle_out = open('obama_text_generation.pickle', 'wb')\n",
        "pickle.dump(obama_text_generation, obama_pickle_out)\n",
        "obama_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D7-wAflNoFc"
      },
      "source": [
        "## Bill Gates Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxW3O5ftNpCh"
      },
      "source": [
        "# select text corpus\n",
        "gates = df[df['Username']== 'Bill Gates']\n",
        "gates_corpus = corpus(gates)\n",
        "\n",
        "text_file = open(\"Bill Gates.txt\", \"w\")\n",
        "n = text_file.write(gates_corpus)\n",
        "text_file.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_8k9i8XN68T",
        "outputId": "f470d32c-609b-44bb-970d-248d27eef1f0"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              'Bill Gates.txt',\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 33143 tokens\n",
            "Training...\n",
            "[10 | 1263.74] loss=3.08 avg=3.08\n",
            "[20 | 2525.53] loss=2.76 avg=2.92\n",
            "[30 | 3796.02] loss=2.26 avg=2.69\n",
            "[40 | 5056.51] loss=2.04 avg=2.53\n",
            "[50 | 6319.67] loss=1.68 avg=2.36\n",
            "[60 | 7578.39] loss=1.01 avg=2.13\n",
            "[70 | 8831.70] loss=0.82 avg=1.93\n",
            "[80 | 10079.23] loss=0.85 avg=1.79\n",
            "[90 | 11321.60] loss=0.27 avg=1.62\n",
            "[100 | 12568.83] loss=0.38 avg=1.49\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4-bN2uEOBlJ"
      },
      "source": [
        " # generate text\n",
        " gates_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-9fOfgbTCp3"
      },
      "source": [
        "# export generated text\n",
        "gates_pickle_out = open('gates_text_generation.pickle', 'wb')\n",
        "pickle.dump(gates_text_generation, gates_pickle_out)\n",
        "gates_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6ekzolAT2Sc"
      },
      "source": [
        "## Conan 'O Brien Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_SxzMGxT5PH"
      },
      "source": [
        "brien = df[df['Username']== \"Conan O'Brien\"]\n",
        "brien_corpus = corpus(brien)\n",
        "\n",
        "text_file = open(\"Conan O' Brien.txt\", \"w\")\n",
        "n = text_file.write(brien_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4b81B6VYJL",
        "outputId": "1d2385ab-5cc3-4f38-a448-cfff08b857d1"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Conan O' Brien.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 23444 tokens\n",
            "Training...\n",
            "[10 | 1295.37] loss=3.91 avg=3.91\n",
            "[20 | 2577.66] loss=3.20 avg=3.55\n",
            "[30 | 3856.86] loss=2.45 avg=3.18\n",
            "[40 | 5126.71] loss=2.08 avg=2.90\n",
            "[50 | 6385.44] loss=1.41 avg=2.60\n",
            "[60 | 7638.18] loss=0.69 avg=2.27\n",
            "[70 | 8891.76] loss=0.47 avg=2.01\n",
            "[80 | 10148.73] loss=0.31 avg=1.79\n",
            "[90 | 11396.56] loss=0.12 avg=1.59\n",
            "[100 | 12644.63] loss=0.13 avg=1.44\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcHYfKRhVhsO"
      },
      "source": [
        "brien_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "gKT8KzvntuLu",
        "outputId": "3e134f64-2c8d-42a6-f493-ee3c2a95ace3"
      },
      "source": [
        "brien_text_generation[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"We\\'re all in this together,\" rapper Future taunted in a series of nasally crooned rants. Now, that\\'s just one person can change the world.take our poll - simple: the person wearing the red and white is giving everyone else a bit of a blow-out.\\n\\nollie cristo is the reason i have a Facebook page. every Saturday at 10pm, i send out a tweet which is instantly thought to be from space. anyway, now someone has to pay for my flight to hell.is anyone else still alive who can take selfies with the apocalypse on video?i\\'m going to be checking out @theggregary this week and i promise to be funny, polite, and just generally nice.  if only there was a better name for the phrase \"death to dinosaurs\"--moonshine.the last door into hell is the last door into an old age temple.yogurt is the healthiest food ever packaged in a container that will last 100 years.yogurt is an animal protein isolate, which means it\\'s 100% natural. my friend @kumailn stopped by to talk about a new book and i-have-no-cluttered-mysteries.  jenga shaped like a parrot but with a large, yellow heart. chew: 1/4-cup (30g) sliced mango\\n\\nbitterly robust mango, packed with essential oils\\n\\nmango-flavored syrups, then frozen until firm\\n\\ntip: you can make these at home! i use a food processor to fine-tune the process, and it\\'s very easy to make small batches of these..@kumailn is one of the most intelligent, funny, and very creative people I\\'ve ever known.  #conanconim protesting the lion king because pumbaa promotes unrealistic expectations. #conanconfound in love with pumbaa. #conancon #conanconnot sure i like the new back-end for my live stream of the prodigiously boring political season. #conanconnot sure i like the new back-end for my live stream of the prodigiously boring political season. #conanconnot sure i like the new back-end for my stream of the prodigiously boring political season. #conanconnotsure about paying the $99 shipping? just grab a potato from the basketide and use it to stream my #conancon live stream. #conanconstarting a new year by decorating my fridge with some delicious fresh produce! #conanconstarting a new year by making me a merlot tequila. #conanconstarting a new year by making me a fresh batch mister papex. #conanconstarting a new year by adding 135ml of alcohol to my water glass. #conanconstarting a new year by lighting a fire to combat the spread of human papilloma voronica. #conanconstarting a new year by teaching my sister ihimself to draw. she\\'s like, 0-2. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year by helping a friend in need. #conanconstarting a new year is like the first time you shower and find yourself wearing only a t-shirt from last year.you know who\\'s popular right now, and has a good career track record?rage when a human life is threatened by a gigantic green dinosaur.when a human life is threatened by a gigantic green dinosaur.when a human life is threatened by a gigantic green dinosaur.when a human life is threatened by a gigantic green dinosaur.when a human life is threatened by a gigantic green dinosaur.when a human life is threatened by a gigantic green dinosaur.when a human life is in jeopardy, threaten the planet with a life-support system.when a human lives in peril, take action right away! #conanconnot sure of all the foodstuffs: high fructose corn syrup, no beans.this is it: there\\'s a food that tastes exactly like ham and you just gotta get it.we\\'re one full moon after the last recorded moon landing.you\\'d think that a healthy dose of skepticism about space travel would be taking a back seat to these disbelief-stricken humans in black.calm down, scientists: this alcohol is just not for you.we\\'re one week away from deciding whether to launch the next generation of the federal government, or support the brave warriors who fought the great war on terror.is anyone else'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRQSmKW0tw4j"
      },
      "source": [
        "brien_pickle_out = open('brien_text_generation.pickle', 'wb')\n",
        "pickle.dump(brien_text_generation, brien_pickle_out)\n",
        "brien_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQjTVs5xvXqS"
      },
      "source": [
        "## Donald Trump Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8W96Dxvgoo"
      },
      "source": [
        "# select text corpus\n",
        "trump = df[df['Username']== \"Donald Trump\"]\n",
        "trump_corpus = corpus(trump)\n",
        "\n",
        "text_file = open(\"Donald Trump.txt\", \"w\")\n",
        "n = text_file.write(trump_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cny0DBqimvRv",
        "outputId": "b27d7aaf-8d64-4641-82fe-5cbece7df253"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Donald Trump.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 187558 tokens\n",
            "Training...\n",
            "[10 | 1310.95] loss=3.62 avg=3.62\n",
            "[20 | 2604.33] loss=3.53 avg=3.57\n",
            "[30 | 3917.52] loss=3.47 avg=3.54\n",
            "[40 | 5202.83] loss=3.28 avg=3.47\n",
            "[50 | 6483.74] loss=3.10 avg=3.40\n",
            "[60 | 7749.14] loss=3.08 avg=3.34\n",
            "[70 | 9055.48] loss=3.16 avg=3.32\n",
            "[80 | 10359.27] loss=2.81 avg=3.25\n",
            "[90 | 11665.62] loss=2.72 avg=3.19\n",
            "[100 | 12971.22] loss=3.00 avg=3.17\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpkBFREsm3_A"
      },
      "source": [
        "# generate text\n",
        "trump_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4IGVsPBSfYv"
      },
      "source": [
        "# export generated text\n",
        "trump_pickle_out = open('trump_text_generation.pickle', 'wb')\n",
        "pickle.dump(trump_text_generation, trump_pickle_out)\n",
        "trump_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKzS4dFaYp-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwh1-2ixYtX5"
      },
      "source": [
        "## Dwayne Johnson Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVuoRzCxYvfB"
      },
      "source": [
        "# select text corpus\n",
        "johnson = df[df['Username']== \"Dwayne Johnson\"]\n",
        "johnson_corpus = corpus(johnson)\n",
        "\n",
        "text_file = open(\"Dwayne Johnson.txt\", \"w\")\n",
        "n = text_file.write(johnson_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0eDesDvdOhI",
        "outputId": "1abb9467-ee57-4816-c2d0-0c29defd85e1"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Dwayne Johnson.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 39828 tokens\n",
            "Training...\n",
            "[10 | 1265.50] loss=3.76 avg=3.76\n",
            "[20 | 2536.73] loss=3.73 avg=3.74\n",
            "[30 | 3817.89] loss=3.64 avg=3.71\n",
            "[40 | 5098.19] loss=2.95 avg=3.52\n",
            "[50 | 6386.95] loss=2.37 avg=3.28\n",
            "[60 | 7667.96] loss=1.96 avg=3.06\n",
            "[70 | 8944.58] loss=1.59 avg=2.84\n",
            "[80 | 10230.40] loss=1.40 avg=2.66\n",
            "[90 | 11516.97] loss=1.11 avg=2.48\n",
            "[100 | 12827.13] loss=1.15 avg=2.34\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0gg9AHRd8Hn"
      },
      "source": [
        "# genreate text\n",
        "dwayne_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8TuGFgPQ06V"
      },
      "source": [
        "# export generated text\n",
        "johnson_pickle_out = open('dwayne_text_generation.pickle', 'wb')\n",
        "pickle.dump(dwayne_text_generation, johnson_pickle_out)\n",
        "johnson_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmNUKYihRB-U"
      },
      "source": [
        "## Elizabeth Warren Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiHPnq5Q-pP"
      },
      "source": [
        "# select text corpus\n",
        "warren = df[df['Username']== \"Elizabeth Warren\"]\n",
        "warren_corpus = corpus(warren)\n",
        "\n",
        "text_file = open(\"Elizabeth Warren.txt\", \"w\")\n",
        "n = text_file.write(warren_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE55qovsRNFk",
        "outputId": "5be17281-9473-441d-d636-d082130482a2"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Elizabeth Warren.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 50443 tokens\n",
            "Training...\n",
            "[10 | 1407.96] loss=3.31 avg=3.31\n",
            "[20 | 2697.27] loss=2.96 avg=3.14\n",
            "[30 | 3934.31] loss=2.60 avg=2.96\n",
            "[40 | 5162.04] loss=2.21 avg=2.77\n",
            "[50 | 6400.23] loss=2.28 avg=2.67\n",
            "[60 | 7638.20] loss=1.78 avg=2.51\n",
            "[70 | 8873.93] loss=1.23 avg=2.33\n",
            "[80 | 10113.63] loss=1.71 avg=2.25\n",
            "[90 | 11359.39] loss=1.13 avg=2.12\n",
            "[100 | 12597.61] loss=0.98 avg=2.00\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbmi39OdW8zO"
      },
      "source": [
        "# generate text\n",
        "warren_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gnsq40EXD4o"
      },
      "source": [
        "# export generated text\n",
        "warren_pickle_out = open('warren_text_generation.pickle', 'wb')\n",
        "pickle.dump(warren_text_generation, warren_pickle_out)\n",
        "warren_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs0k8qsXwH7P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG9Z085CVKfi"
      },
      "source": [
        "## Ellen DeGeneres Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Te5qGAqVQ2A"
      },
      "source": [
        "# select text corpus\n",
        "DeGeneres = df[df['Username']== \"Ellen DeGeneres\"]\n",
        "DeGeneres_corpus = corpus(DeGeneres)\n",
        "\n",
        "text_file = open(\"Ellen DeGeneres.txt\", \"w\")\n",
        "n = text_file.write(DeGeneres_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJSc6LScVSnS",
        "outputId": "295c5bbb-bc1b-4954-a3ca-0bc48b46618d"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Ellen DeGeneres.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 23490 tokens\n",
            "Training...\n",
            "[10 | 1270.43] loss=3.72 avg=3.72\n",
            "[20 | 2541.75] loss=2.94 avg=3.33\n",
            "[30 | 3818.17] loss=2.38 avg=3.01\n",
            "[40 | 5094.53] loss=2.00 avg=2.75\n",
            "[50 | 6366.42] loss=1.51 avg=2.50\n",
            "[60 | 7633.23] loss=1.17 avg=2.27\n",
            "[70 | 8898.70] loss=0.77 avg=2.05\n",
            "[80 | 10177.28] loss=0.48 avg=1.85\n",
            "[90 | 11462.99] loss=0.25 avg=1.66\n",
            "[100 | 12752.55] loss=0.14 avg=1.50\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6FApLTVU2a"
      },
      "source": [
        "# generate text\n",
        "DeGeneres_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "469OJsT0VohI",
        "outputId": "9bdca100-8f6e-4f74-9815-f4a5f3074223"
      },
      "source": [
        "# export generated text\n",
        "DeGeneres_pickle_out = open('Degeneres_text_generation.pickle', 'wb')\n",
        "pickle.dump(DeGeneres_text_generation, DeGeneres_pickle_out)\n",
        "DeGeneres_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-179e4dc5f925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDeGeneres_pickle_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Degeneres_text_generation.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeGeneres_text_generation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeGeneres_pickle_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mDeGeneres_pickle_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdKHZGoRVwDj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0olWxgh9OWs"
      },
      "source": [
        "## Elon Musk Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja7R2AQk9RDn"
      },
      "source": [
        "# select text corpus\n",
        "musk = df[df['Username']== \"Elon Musk\"]\n",
        "musk_corpus = corpus(musk)\n",
        "\n",
        "text_file = open(\"Elon Musk.txt\", \"w\")\n",
        "n = text_file.write(musk_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyCMJTj69Z_p",
        "outputId": "fb6dd0ad-342f-4aea-b006-ee33969faf1a"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Elon Musk.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1672.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 4104 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1323.48] loss=2.95 avg=2.95\n",
            "[20 | 2696.15] loss=1.57 avg=2.26\n",
            "[30 | 4066.95] loss=0.16 avg=1.55\n",
            "[40 | 5426.61] loss=0.04 avg=1.17\n",
            "[50 | 6774.23] loss=0.03 avg=0.94\n",
            "[60 | 8127.05] loss=0.04 avg=0.78\n",
            "[70 | 9516.00] loss=0.02 avg=0.67\n",
            "[80 | 10918.60] loss=0.03 avg=0.59\n",
            "[90 | 12347.46] loss=0.02 avg=0.52\n",
            "[100 | 13760.76] loss=0.02 avg=0.47\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxj4c0DH9gmJ"
      },
      "source": [
        "# generate text\n",
        "musk_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5FDCc2u9lxJ"
      },
      "source": [
        "# export genreated text\n",
        "musk_pickle_out = open('musk_text_generation.pickle', 'wb')\n",
        "pickle.dump(musk_text_generation, musk_pickle_out)\n",
        "musk_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_m1fjdmeN93"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Vc-3D1FKun"
      },
      "source": [
        "## Emma Watson Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqjPyOnBFNu4"
      },
      "source": [
        "# select text corpus\n",
        "watson = df[df['Username']== \"Emma Watson\"]\n",
        "watson_corpus = corpus(watson)\n",
        "\n",
        "text_file = open(\"Emma Watson.txt\", \"w\")\n",
        "n = text_file.write(watson_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV4X5jKAFaqD",
        "outputId": "3d169b13-2fb5-4612-8281-d0f2f90ac3a6"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Emma Watson.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 18237 tokens\n",
            "Training...\n",
            "[10 | 960.24] loss=4.04 avg=4.04\n",
            "[20 | 1942.12] loss=2.99 avg=3.51\n",
            "[30 | 2940.59] loss=2.54 avg=3.19\n",
            "[40 | 3966.86] loss=2.00 avg=2.89\n",
            "[50 | 4986.35] loss=1.02 avg=2.50\n",
            "[60 | 6006.91] loss=0.67 avg=2.19\n",
            "[70 | 7015.56] loss=0.22 avg=1.90\n",
            "[80 | 8024.18] loss=0.11 avg=1.67\n",
            "[90 | 9028.24] loss=0.12 avg=1.49\n",
            "[100 | 10039.10] loss=0.07 avg=1.34\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "345lDWDBFbeS"
      },
      "source": [
        "# generate text\n",
        "watson_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7k_q4sCFgwV"
      },
      "source": [
        "# export generated text\n",
        "watson_pickle_out = open('watson_text_generation.pickle', 'wb')\n",
        "pickle.dump(watson_text_generation, watson_pickle_out)\n",
        "watson_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpSxJy0L26RR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGKOhaLkrxko"
      },
      "source": [
        "## Gordon Ramsay Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHgJ6dfor0q9"
      },
      "source": [
        "# select text corpus\n",
        "ramsay = df[df['Username']== \"Gordon Ramsay\"]\n",
        "ramsay_corpus = corpus(ramsay)\n",
        "\n",
        "text_file = open(\"Gordon Ramsay.txt\", \"w\")\n",
        "n = text_file.write(ramsay_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI7YLuNar8Q3",
        "outputId": "437c0502-2028-4730-ec59-dd32a762c85b"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Gordon Ramsay.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 23556 tokens\n",
            "Training...\n",
            "[10 | 1207.78] loss=3.22 avg=3.22\n",
            "[20 | 2434.26] loss=2.93 avg=3.08\n",
            "[30 | 3678.17] loss=2.51 avg=2.89\n",
            "[40 | 4928.24] loss=2.03 avg=2.67\n",
            "[50 | 6172.69] loss=1.38 avg=2.41\n",
            "[60 | 7404.34] loss=1.00 avg=2.17\n",
            "[70 | 8626.17] loss=0.54 avg=1.93\n",
            "[80 | 9853.56] loss=0.28 avg=1.71\n",
            "[90 | 11080.59] loss=0.17 avg=1.54\n",
            "[100 | 12310.50] loss=0.11 avg=1.39\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq_tgNSIr_QN"
      },
      "source": [
        "# generate text\n",
        "ramsay_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJzvhxbvsDuv"
      },
      "source": [
        "# export generated text\n",
        "ramsay_pickle_out = open('ramsay_text_generation.pickle', 'wb')\n",
        "pickle.dump(ramsay_text_generation, ramsay_pickle_out)\n",
        "ramsay_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtwyJ7HZjJ2s"
      },
      "source": [
        "## Jeff Weiner Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOgacMtpjRrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "03584a37-9970-40f2-a596-248ccc1809bd"
      },
      "source": [
        "# select text corpus\n",
        "weiner = df[df['Username']== \"Jeff Weiner\"]\n",
        "weiner_corpus = corpus(weiner)\n",
        "\n",
        "text_file = open(\"Jeff Weiner.txt\", \"w\")\n",
        "n = text_file.write(weiner_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0276bf797cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweiner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Username'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"Jeff Weiner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweiner_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweiner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jeff Weiner.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweiner_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXNBqDRijZJR"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Jeff Weiner.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW_AZwJsjc2b"
      },
      "source": [
        "# generate text\n",
        "weiner_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBpI0_rbjhEU"
      },
      "source": [
        "# export generated text\n",
        "weiner_pickle_out = open('weiner_text_generation.pickle', 'wb')\n",
        "pickle.dump(weiner_text_generation, weiner_pickle_out)\n",
        "weiner_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P3rIzA5_UOw"
      },
      "source": [
        "## Joe Biden Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMbbx91fOgH2"
      },
      "source": [
        "# select text corpus\n",
        "biden = df[df['Username']== \"Joe Biden\"]\n",
        "biden_corpus = corpus(biden)\n",
        "\n",
        "text_file = open(\"Joe Biden.txt\", \"w\")\n",
        "n = text_file.write(biden_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9O1bBz7_eXt",
        "outputId": "5dc2b1ef-8acd-4af3-e9ce-eea3377b255b"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Joe Biden.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 223773 tokens\n",
            "Training...\n",
            "[10 | 1215.61] loss=3.09 avg=3.09\n",
            "[20 | 2438.95] loss=3.00 avg=3.04\n",
            "[30 | 3670.56] loss=2.83 avg=2.97\n",
            "[40 | 4902.98] loss=3.01 avg=2.98\n",
            "[50 | 6134.48] loss=2.71 avg=2.93\n",
            "[60 | 7363.84] loss=2.58 avg=2.87\n",
            "[70 | 8590.78] loss=2.65 avg=2.83\n",
            "[80 | 9815.64] loss=2.67 avg=2.81\n",
            "[90 | 11041.41] loss=2.50 avg=2.78\n",
            "[100 | 12272.50] loss=2.41 avg=2.74\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0gLmPJl_hAf"
      },
      "source": [
        "# generate text\n",
        "biden_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZGZtQHO_mPQ"
      },
      "source": [
        "# export generated text\n",
        "biden_pickle_out = open('biden_text_generation.pickle', 'wb')\n",
        "pickle.dump(biden_text_generation, biden_pickle_out)\n",
        "biden_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJr87p-B_xA-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbKLyQvVei_W"
      },
      "source": [
        "## John Cena Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17h2roNnemF6"
      },
      "source": [
        "# select text corpus\n",
        "cena = df[df['Username']== \"John Cena\"]\n",
        "cena_corpus = corpus(cena)\n",
        "\n",
        "text_file = open(\"John Cena.txt\", \"w\")\n",
        "n = text_file.write(cena_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVJ9ReVevKQ",
        "outputId": "25d84494-28f5-48db-f1cd-385af1e40234"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"John Cena.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 34840 tokens\n",
            "Training...\n",
            "[10 | 1260.03] loss=3.31 avg=3.31\n",
            "[20 | 2504.50] loss=2.98 avg=3.15\n",
            "[30 | 3747.92] loss=2.80 avg=3.03\n",
            "[40 | 4988.71] loss=2.34 avg=2.85\n",
            "[50 | 6234.30] loss=2.07 avg=2.69\n",
            "[60 | 7474.64] loss=1.48 avg=2.49\n",
            "[70 | 8711.62] loss=1.26 avg=2.31\n",
            "[80 | 9950.28] loss=0.66 avg=2.09\n",
            "[90 | 11188.35] loss=0.78 avg=1.94\n",
            "[100 | 12427.21] loss=0.38 avg=1.78\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6M2FENzewtp"
      },
      "source": [
        "# generate text\n",
        "cena_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJHMQu_8e2DS"
      },
      "source": [
        "# export generated text\n",
        "cena_pickle_out = open('cena_text_generation.pickle', 'wb')\n",
        "pickle.dump(cena_text_generation, cena_pickle_out)\n",
        "cena_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q17aBjgtfMpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ahfm-OMRzfq"
      },
      "source": [
        "## Kevin Durant Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKaYHN14R1qW"
      },
      "source": [
        "# select text corpus\n",
        "durant = df[df['Username']== \"Kevin Durant\"]\n",
        "durant_corpus = corpus(durant)\n",
        "\n",
        "text_file = open(\"Kevin Durant.txt\", \"w\")\n",
        "n = text_file.write(durant_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-bvoPswR8hT",
        "outputId": "874ec631-5fd5-43a7-b3d0-a52805775d17"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Kevin Durant.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 16311 tokens\n",
            "Training...\n",
            "[10 | 1232.48] loss=3.95 avg=3.95\n",
            "[20 | 2499.29] loss=3.26 avg=3.60\n",
            "[30 | 3762.00] loss=2.62 avg=3.27\n",
            "[40 | 5022.03] loss=1.68 avg=2.87\n",
            "[50 | 6283.38] loss=1.09 avg=2.51\n",
            "[60 | 7542.83] loss=0.53 avg=2.17\n",
            "[70 | 8804.59] loss=0.21 avg=1.88\n",
            "[80 | 10069.12] loss=0.34 avg=1.68\n",
            "[90 | 11332.57] loss=0.08 avg=1.49\n",
            "[100 | 12591.74] loss=0.06 avg=1.34\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnVZ5u44SAEt"
      },
      "source": [
        "# generate text\n",
        "durant_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRr43w7ISDpZ"
      },
      "source": [
        "# export generated text\n",
        "durant_pickle_out = open('durant_text_generation.pickle', 'wb')\n",
        "pickle.dump(durant_text_generation, durant_pickle_out)\n",
        "durant_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqfY1LYLUz_u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XVzJD3UHi8Q"
      },
      "source": [
        "## Kevin Hart Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVxxyeprHk2E"
      },
      "source": [
        "# select text corpus\n",
        "hart = df[df['Username']== \"Kevin Hart\"]\n",
        "hart_corpus = corpus(hart)\n",
        "\n",
        "text_file = open(\"Kevin Hart.txt\", \"w\")\n",
        "n = text_file.write(hart_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsyHpZ8qHtDA",
        "outputId": "03e9de2d-434e-4da5-8591-583b19f55d71"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Kevin Hart.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 12853 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1261.27] loss=3.44 avg=3.44\n",
            "[20 | 2520.90] loss=2.41 avg=2.92\n",
            "[30 | 3785.53] loss=1.53 avg=2.45\n",
            "[40 | 5052.17] loss=0.91 avg=2.06\n",
            "[50 | 6312.74] loss=0.68 avg=1.78\n",
            "[60 | 7562.33] loss=0.18 avg=1.51\n",
            "[70 | 8798.52] loss=0.10 avg=1.30\n",
            "[80 | 10040.63] loss=0.06 avg=1.14\n",
            "[90 | 11285.56] loss=0.11 avg=1.02\n",
            "[100 | 12532.56] loss=0.05 avg=0.92\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXOrDHAWHuce"
      },
      "source": [
        "# generate text\n",
        "hart_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6qrCZnHylr"
      },
      "source": [
        "# export generated text\n",
        "hart_pickle_out = open('hart_text_generation.pickle', 'wb')\n",
        "pickle.dump(hart_text_generation, hart_pickle_out)\n",
        "hart_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD6ckErjXvmH"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3GvUsKINlX8"
      },
      "source": [
        "## Kylie Jenner Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPQ9KC9NnPz"
      },
      "source": [
        "# select text corpus\n",
        "jenner = df[df['Username']== \"Kylie Jenner\"]\n",
        "jenner_corpus = corpus(jenner)\n",
        "\n",
        "text_file = open(\"Kylie Jenner.txt\", \"w\")\n",
        "n = text_file.write(jenner_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8HvhZa3Ntqh",
        "outputId": "626d5027-3d7e-435c-b13b-00aed042d180"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Kylie Jenner.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 19060 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1187.44] loss=2.96 avg=2.96\n",
            "[20 | 2402.22] loss=2.51 avg=2.73\n",
            "[30 | 3626.58] loss=1.97 avg=2.48\n",
            "[40 | 4852.02] loss=1.71 avg=2.28\n",
            "[50 | 6083.39] loss=1.44 avg=2.11\n",
            "[60 | 7294.64] loss=0.78 avg=1.88\n",
            "[70 | 8501.90] loss=0.60 avg=1.69\n",
            "[80 | 9710.36] loss=0.33 avg=1.52\n",
            "[90 | 10922.15] loss=0.14 avg=1.36\n",
            "[100 | 12131.60] loss=0.11 avg=1.23\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUTKfokuNwxf"
      },
      "source": [
        "# generate text\n",
        "jenner_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewb3BwgwN0jz"
      },
      "source": [
        "# export generated text\n",
        "jenner_pickle_out = open('jenner_text_generation.pickle', 'wb')\n",
        "pickle.dump(jenner_text_generation, jenner_pickle_out)\n",
        "jenner_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMf6HcuY4cPo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEKK0epZkGGl"
      },
      "source": [
        "## Lady Gaga Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OazRfbFxkIWQ"
      },
      "source": [
        "# select text corpus\n",
        "gaga = df[df['Username']== \"Lady Gaga\"]\n",
        "gaga_corpus = corpus(gaga)\n",
        "\n",
        "text_file = open(\"Lady Gaga.txt\", \"w\")\n",
        "n = text_file.write(gaga_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfSWWgFpkPyS",
        "outputId": "2959310a-d9bb-43ef-e88f-e62a39bb6283"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Lady Gaga.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 24459 tokens\n",
            "Training...\n",
            "[10 | 1197.54] loss=3.56 avg=3.56\n",
            "[20 | 2410.74] loss=3.00 avg=3.28\n",
            "[30 | 3635.18] loss=2.65 avg=3.07\n",
            "[40 | 4865.82] loss=2.33 avg=2.88\n",
            "[50 | 6084.61] loss=1.57 avg=2.61\n",
            "[60 | 7315.81] loss=1.10 avg=2.35\n",
            "[70 | 8529.42] loss=0.86 avg=2.13\n",
            "[80 | 9744.70] loss=0.43 avg=1.91\n",
            "[90 | 10956.46] loss=0.27 avg=1.72\n",
            "[100 | 12168.79] loss=0.16 avg=1.56\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf79Qi4BkU6Z"
      },
      "source": [
        "# generate text\n",
        "gaga_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6_WCOZkZh8"
      },
      "source": [
        "# export generated text\n",
        "gaga_pickle_out = open('gaga_text_generation.pickle', 'wb')\n",
        "pickle.dump(gaga_text_generation, gaga_pickle_out)\n",
        "gaga_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQJD1aVdrCvr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ryIKKxbk5F"
      },
      "source": [
        "## LeBron James Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdrewOBMbmyP"
      },
      "source": [
        "# select text corpus\n",
        "james = df[df['Username']== \"LeBron James\"]\n",
        "james_corpus = corpus(james)\n",
        "\n",
        "text_file = open(\"Lebron James.txt\", \"w\")\n",
        "n = text_file.write(james_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAg4io9Abvym",
        "outputId": "d67c0c1e-2807-44f7-d463-85d0f2b750cb"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Lebron James.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 18536 tokens\n",
            "Training...\n",
            "[10 | 1323.39] loss=4.13 avg=4.13\n",
            "[20 | 2644.73] loss=3.33 avg=3.73\n",
            "[30 | 3972.56] loss=2.96 avg=3.47\n",
            "[40 | 5284.33] loss=2.49 avg=3.22\n",
            "[50 | 6582.50] loss=1.45 avg=2.86\n",
            "[60 | 7879.47] loss=0.91 avg=2.53\n",
            "[70 | 9178.72] loss=0.52 avg=2.23\n",
            "[80 | 10478.45] loss=0.36 avg=1.99\n",
            "[90 | 11779.20] loss=0.15 avg=1.78\n",
            "[100 | 13074.58] loss=0.07 avg=1.60\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMhoxkCDbypX"
      },
      "source": [
        "# generate text\n",
        "james_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmQjcvyub10X"
      },
      "source": [
        "# export generated text\n",
        "james_pickle_out = open('james_text_generation.pickle', 'wb')\n",
        "pickle.dump(james_text_generation, james_pickle_out)\n",
        "james_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-qxyfhVekI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAQ-RHSPJbJF"
      },
      "source": [
        "## Louis Tomlinson Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNj5yCe-JdIr"
      },
      "source": [
        "# select text corpus\n",
        "tomlinson = df[df['Username']== \"Louis Tomlinson\"]\n",
        "tomlinson_corpus = corpus(tomlinson)\n",
        "\n",
        "text_file = open(\"Louis Tomlinson.txt\", \"w\")\n",
        "n = text_file.write(tomlinson_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yUOP7KxJnl5",
        "outputId": "dbdf28ae-87e3-4daa-bf60-2d9dd5a2a67c"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Louis Tomlinson.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 16523 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1214.89] loss=3.16 avg=3.16\n",
            "[20 | 2417.43] loss=2.67 avg=2.91\n",
            "[30 | 3630.82] loss=2.31 avg=2.71\n",
            "[40 | 4834.11] loss=1.61 avg=2.43\n",
            "[50 | 6030.75] loss=1.01 avg=2.14\n",
            "[60 | 7231.46] loss=0.46 avg=1.85\n",
            "[70 | 8436.67] loss=0.34 avg=1.63\n",
            "[80 | 9632.26] loss=0.22 avg=1.45\n",
            "[100 | 12019.49] loss=0.06 avg=1.16\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaLr1psEJqLn"
      },
      "source": [
        "# generate text\n",
        "tomlinson_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQdD6ICTJvEZ"
      },
      "source": [
        "# export generated text\n",
        "tomlinson_pickle_out = open('tomlinson_text_generation.pickle', 'wb')\n",
        "pickle.dump(tomlinson_text_generation, tomlinson_pickle_out)\n",
        "tomlinson_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i92nsH6abN-h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTevtbZaWWjd"
      },
      "source": [
        "## Mariah Carey Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcWa9M5nWZAs"
      },
      "source": [
        "# select text corpus\n",
        "carey = df[df['Username']== \"Mariah Carey\"]\n",
        "carey_corpus = corpus(carey)\n",
        "\n",
        "text_file = open(\"Mariah Carey.txt\", \"w\")\n",
        "n = text_file.write(carey_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLrML-ssWh5z",
        "outputId": "eb55ff43-e9ec-4c67-9547-799da6ec9474"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Mariah Carey.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 20601 tokens\n",
            "Training...\n",
            "[10 | 1217.20] loss=3.48 avg=3.48\n",
            "[20 | 2439.39] loss=2.87 avg=3.17\n",
            "[30 | 3672.39] loss=2.53 avg=2.96\n",
            "[40 | 4917.34] loss=1.97 avg=2.71\n",
            "[50 | 6175.03] loss=1.03 avg=2.36\n",
            "[60 | 7451.86] loss=0.63 avg=2.07\n",
            "[70 | 8695.96] loss=0.35 avg=1.82\n",
            "[80 | 9938.77] loss=0.29 avg=1.62\n",
            "[90 | 11180.71] loss=0.17 avg=1.45\n",
            "[100 | 12417.32] loss=0.17 avg=1.32\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJWbnyiWk4O"
      },
      "source": [
        "# generate text\n",
        "carey_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmMB1SX0Wp-p"
      },
      "source": [
        "# export generated text\n",
        "carey_pickle_out = open('carey_text_generation.pickle', 'wb')\n",
        "pickle.dump(carey_text_generation, carey_pickle_out)\n",
        "carey_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lo2q2diW0E8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HOg69RuW0px"
      },
      "source": [
        "## Neil Patrick Harris Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc9DuDrXW5SH"
      },
      "source": [
        "# select text corpus\n",
        "harris = df[df['Username']== \"Neil Patrick Harris\"]\n",
        "harris_corpus = corpus(harris)\n",
        "\n",
        "text_file = open(\"Neil Patrick Harris.txt\", \"w\")\n",
        "n = text_file.write(harris_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEge3JNBXAZ6",
        "outputId": "7e18d650-e3bf-4d6d-ab39-4cef8945c73f"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Neil Patrick Harris.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 31639 tokens\n",
            "Training...\n",
            "[10 | 1246.38] loss=4.21 avg=4.21\n",
            "[20 | 2483.92] loss=3.62 avg=3.91\n",
            "[30 | 3749.34] loss=3.25 avg=3.69\n",
            "[40 | 5019.89] loss=2.66 avg=3.43\n",
            "[50 | 6336.95] loss=2.20 avg=3.18\n",
            "[60 | 7677.10] loss=1.54 avg=2.90\n",
            "[70 | 8967.19] loss=1.08 avg=2.63\n",
            "[80 | 10225.98] loss=0.81 avg=2.39\n",
            "[90 | 11580.15] loss=0.33 avg=2.16\n",
            "[100 | 12868.92] loss=0.40 avg=1.97\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVgBQVgkXDSH"
      },
      "source": [
        "# generate text\n",
        "harris_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "punJtzIWXHg0"
      },
      "source": [
        "# export generated text\n",
        "harris_pickle_out = open('harris_text_generation.pickle', 'wb')\n",
        "pickle.dump(harris_text_generation, harris_pickle_out)\n",
        "harris_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkYsbWpjEN3N"
      },
      "source": [
        "## Oprah Winfrey Text Generation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG_TDj4zEP7-"
      },
      "source": [
        "# select text corpus\n",
        "winfrey = df[df['Username']== \"Oprah Winfrey\"]\n",
        "winfrey_corpus = corpus(winfrey)\n",
        "\n",
        "text_file = open(\"Oprah Winfrey.txt\", \"w\")\n",
        "n = text_file.write(winfrey_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbMRGdrYERcS",
        "outputId": "c501364a-c01d-4139-a584-7b31dc06061b"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Oprah Winfrey.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 31433 tokens\n",
            "Training...\n",
            "[10 | 1236.68] loss=3.36 avg=3.36\n",
            "[20 | 2520.23] loss=3.12 avg=3.24\n",
            "[30 | 3815.31] loss=2.57 avg=3.01\n",
            "[40 | 5090.11] loss=2.42 avg=2.86\n",
            "[50 | 6343.26] loss=1.84 avg=2.65\n",
            "[60 | 7560.92] loss=1.70 avg=2.49\n",
            "[70 | 8789.54] loss=1.09 avg=2.28\n",
            "[80 | 10018.36] loss=0.91 avg=2.11\n",
            "[90 | 11245.67] loss=0.49 avg=1.92\n",
            "[100 | 12471.75] loss=0.42 avg=1.76\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nUde1RMERgq"
      },
      "source": [
        "# generate text\n",
        "winfrey_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYN8FZ3Eghc"
      },
      "source": [
        "# export generated text\n",
        "winfrey_pickle_out = open('winfrey_text_generation.pickle', 'wb')\n",
        "pickle.dump(winfrey_text_generation, winfrey_pickle_out)\n",
        "winfrey_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc5uPZFdF78a"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7x5gt78F3rk"
      },
      "source": [
        "## Pope Francis Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kztgcDW7F5go"
      },
      "source": [
        "# select text corpus\n",
        "francis = df[df['Username']== \"Pope Francis\"]\n",
        "francis_corpus = corpus(francis)\n",
        "\n",
        "text_file = open(\"Pope Francis.txt\", \"w\")\n",
        "n = text_file.write(francis_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD3Jj48-GBv_",
        "outputId": "5851aa22-9960-4422-f12d-fd68164362d3"
      },
      "source": [
        "# train model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Pope Francis.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 45034 tokens\n",
            "Training...\n",
            "[10 | 1274.50] loss=3.17 avg=3.17\n",
            "[20 | 2538.53] loss=2.75 avg=2.96\n",
            "[30 | 3798.52] loss=2.47 avg=2.79\n",
            "[40 | 5052.36] loss=2.51 avg=2.72\n",
            "[50 | 6307.87] loss=2.25 avg=2.63\n",
            "[60 | 7563.52] loss=1.71 avg=2.47\n",
            "[70 | 8829.09] loss=1.80 avg=2.37\n",
            "[80 | 10089.90] loss=1.42 avg=2.25\n",
            "[90 | 11349.44] loss=1.23 avg=2.13\n",
            "[100 | 12610.64] loss=0.68 avg=1.98\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbwQJMALGEKG"
      },
      "source": [
        "# generate text\n",
        "francis_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpUwo4CuGKzi"
      },
      "source": [
        "# export generated text\n",
        "francis_pickle_out = open('francis_text_generation.pickle', 'wb')\n",
        "pickle.dump(francis_text_generation, francis_pickle_out)\n",
        "francis_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqcSgeT3Gqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNm3kQT23IaO"
      },
      "source": [
        "## Ronda Rousey Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLGDKir3Knp"
      },
      "source": [
        "# select text corpus\n",
        "rousey = df[df['Username']== \"Ronda Rousey\"]\n",
        "rousey_corpus = corpus(rousey)\n",
        "\n",
        "text_file = open(\"Ronda Rousey.txt\", \"w\")\n",
        "n = text_file.write(rousey_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APBZco2g3Qfe",
        "outputId": "d57d122c-f5db-4e80-8611-c996f0d8212d"
      },
      "source": [
        "# train the model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Ronda Rousey.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 28572 tokens\n",
            "Training...\n",
            "[10 | 1229.50] loss=3.45 avg=3.45\n",
            "[20 | 2452.71] loss=3.04 avg=3.24\n",
            "[30 | 3682.89] loss=2.81 avg=3.10\n",
            "[40 | 4899.26] loss=2.12 avg=2.85\n",
            "[50 | 6113.34] loss=1.71 avg=2.62\n",
            "[60 | 7331.07] loss=1.13 avg=2.36\n",
            "[70 | 8551.20] loss=1.06 avg=2.17\n",
            "[80 | 9765.89] loss=0.48 avg=1.95\n",
            "[90 | 10986.82] loss=0.44 avg=1.78\n",
            "[100 | 12202.29] loss=0.29 avg=1.62\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip876Sl23TDQ"
      },
      "source": [
        "# generate text\n",
        "rousey_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_FP6pIP3Wbg"
      },
      "source": [
        "# export generated text\n",
        "rousey_pickle_out = open('rousey_text_generation.pickle', 'wb')\n",
        "pickle.dump(rousey_text_generation, rousey_pickle_out)\n",
        "rousey_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sLZrFljITjw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n6pcJ-7EmfG"
      },
      "source": [
        "## Tim Cook Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoO_e4HNEu4r"
      },
      "source": [
        "# select the text corpus\n",
        "cook = df[df['Username']== \"Tim Cook\"]\n",
        "cook_corpus = corpus(cook)\n",
        "\n",
        "text_file = open(\"Tim Cook.txt\", \"w\")\n",
        "n = text_file.write(cook_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g67i0RME0_U",
        "outputId": "3e3ce966-bf72-45c4-e28a-9366f2757d91"
      },
      "source": [
        "# train the model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Tim Cook.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 34709 tokens\n",
            "Training...\n",
            "[10 | 930.18] loss=3.43 avg=3.43\n",
            "[20 | 1848.70] loss=3.14 avg=3.29\n",
            "[30 | 2766.73] loss=2.96 avg=3.18\n",
            "[40 | 3686.54] loss=2.25 avg=2.94\n",
            "[50 | 4621.43] loss=1.96 avg=2.74\n",
            "[60 | 5567.46] loss=1.66 avg=2.56\n",
            "[70 | 6513.79] loss=1.15 avg=2.35\n",
            "[80 | 7462.26] loss=0.79 avg=2.15\n",
            "[90 | 8409.89] loss=0.72 avg=1.98\n",
            "[100 | 9353.87] loss=0.47 avg=1.82\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1GnPY4BE3gE"
      },
      "source": [
        "# generate text\n",
        "cook_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NufadYHOE63v"
      },
      "source": [
        "# export the generated text\n",
        "cook_pickle_out = open('cook_text_generation.pickle', 'wb')\n",
        "pickle.dump(cook_text_generation, cook_pickle_out)\n",
        "cook_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWJ5okYdHOwj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmxcZ7ddczOw"
      },
      "source": [
        "## Wiz Khalifa Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbM5-Hpc0-f"
      },
      "source": [
        "# select the text corpus\n",
        "khalifa = df[df['Username']== \"Wiz Khalifa\"]\n",
        "khalifa_corpus = corpus(khalifa)\n",
        "\n",
        "text_file = open(\"Wiz Khalifa.txt\", \"w\")\n",
        "n = text_file.write(khalifa_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj-XM-mnc2iB",
        "outputId": "460499b4-5f63-44c3-dd99-43dbdaaf4804"
      },
      "source": [
        "# train the model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Wiz Khalifa.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 722.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 11544 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 878.06] loss=4.03 avg=4.03\n",
            "[20 | 1741.04] loss=2.97 avg=3.50\n",
            "[30 | 2604.42] loss=2.06 avg=3.02\n",
            "[40 | 3462.18] loss=1.16 avg=2.55\n",
            "[50 | 4333.96] loss=0.34 avg=2.10\n",
            "[60 | 5216.81] loss=0.10 avg=1.76\n",
            "[70 | 6100.20] loss=0.17 avg=1.52\n",
            "[80 | 6983.11] loss=0.04 avg=1.33\n",
            "[90 | 7856.18] loss=0.03 avg=1.18\n",
            "[100 | 8711.44] loss=0.04 avg=1.06\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2V6XLUdc4O0"
      },
      "source": [
        "# generate text\n",
        "khalifa_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTmswH8Uc66p"
      },
      "source": [
        "# export the generated text\n",
        "khalifa_pickle_out = open('khalifa_text_generation.pickle', 'wb')\n",
        "pickle.dump(khalifa_text_generation, khalifa_pickle_out)\n",
        "khalifa_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqLhAs1WdsqO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYsvh9LlFZ5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv-s31t6Fdcj"
      },
      "source": [
        "## jimmy fallon Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAaFg6jFfj6"
      },
      "source": [
        "# select the text corpus\n",
        "fallon = df[df['Username']== \"jimmy fallon\"]\n",
        "fallon_corpus = corpus(fallon)\n",
        "\n",
        "text_file = open(\"jimmy fallon.txt\", \"w\")\n",
        "n = text_file.write(fallon_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts-olgnoFlrS",
        "outputId": "ae0ebbe1-a9fd-4fcc-af47-710ebb7ba616"
      },
      "source": [
        "# train the model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"jimmy fallon.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 25204 tokens\n",
            "Training...\n",
            "[10 | 1266.20] loss=3.60 avg=3.60\n",
            "[20 | 2529.38] loss=2.70 avg=3.15\n",
            "[30 | 3803.74] loss=2.38 avg=2.89\n",
            "[40 | 5076.73] loss=1.87 avg=2.63\n",
            "[50 | 6338.29] loss=1.12 avg=2.33\n",
            "[60 | 7614.74] loss=0.85 avg=2.07\n",
            "[70 | 8864.07] loss=0.68 avg=1.87\n",
            "[80 | 10120.50] loss=0.53 avg=1.70\n",
            "[90 | 11378.56] loss=0.36 avg=1.54\n",
            "[100 | 12630.32] loss=0.20 avg=1.40\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C4-27uCFoZG"
      },
      "source": [
        "# generate text with the model\n",
        "fallon_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjNj8Z1sFs9C"
      },
      "source": [
        "# export the data\n",
        "fallon_pickle_out = open('fallon_text_generation.pickle', 'wb')\n",
        "pickle.dump(fallon_text_generation, fallon_pickle_out)\n",
        "fallon_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBLs5C4BGFw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke9aDOe4GIgZ"
      },
      "source": [
        "## Harry Styles Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Y5NJ8DGIUf"
      },
      "source": [
        "# select the text corpus\n",
        "styles = df[df['Username']== \"Harry Styles.\"]\n",
        "styles_corpus = corpus(styles)\n",
        "\n",
        "text_file = open(\"Harry Styles.txt\", \"w\")\n",
        "n = text_file.write(styles_corpus)\n",
        "text_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eyWwBAtGNfw",
        "outputId": "a633dce6-2454-457f-e9de-9ad94bd2f7ef"
      },
      "source": [
        "# train the model\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              \"Harry Styles.txt\",\n",
        "              model_name='124M',\n",
        "              restore_from='fresh',\n",
        "              print_every=10,\n",
        "              steps=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 14557 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 | 1357.40] loss=2.96 avg=2.96\n",
            "[20 | 2722.76] loss=2.21 avg=2.59\n",
            "[30 | 4060.14] loss=1.48 avg=2.21\n",
            "[40 | 5405.45] loss=1.12 avg=1.94\n",
            "[50 | 6749.38] loss=0.69 avg=1.68\n",
            "[60 | 8091.33] loss=0.41 avg=1.47\n",
            "[70 | 9433.55] loss=0.16 avg=1.27\n",
            "[80 | 10787.51] loss=0.07 avg=1.12\n",
            "[90 | 12138.07] loss=0.07 avg=1.00\n",
            "[100 | 13486.10] loss=0.05 avg=0.90\n",
            "Saving checkpoint/run1/model-100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNJjfBhdGQC-"
      },
      "source": [
        "# generate text with model\n",
        "styles_text_generation = gpt2.generate(sess, run_name='run1', nsamples=5, batch_size=5, return_as_list=True, temperature=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFnID0wWGS0m"
      },
      "source": [
        "# export data\n",
        "styles_pickle_out = open('styles_text_generation.pickle', 'wb')\n",
        "pickle.dump(styles_text_generation, styles_pickle_out)\n",
        "styles_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGwf3_PpGkcP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}