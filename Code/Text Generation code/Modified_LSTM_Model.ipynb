{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modified LSTM Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH5G0rXUEP9g"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5u0wEIlEU1D"
      },
      "source": [
        "This file displays the code for building the modified LSTM model and then using it to generate text for each celebrity. \n",
        "\n",
        "The steps are as follows:\n",
        "\n",
        "1. Load the data for the celebrity in question\n",
        "2. Convert the text into pairs of sequences and output characters that will serve as the input and output of the model respectively\n",
        "3. Build the LSTM model.\n",
        "4. Train the model with the processed data.\n",
        "5. Use the model to generate text.\n",
        "6. Export the generated text with pickle. \n",
        "7. Repeat steps 1-6 for all celebrities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsZIg7s4G-Pp"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  print('File not in drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AqfTVPZHD-_"
      },
      "source": [
        "# import libraries\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY2E_iN-rE_Q"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROH2j3Zc6Kuf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "E9Z_FWP2HEEE",
        "outputId": "e83c741a-ddf0-4c04-d203-363ac17ef8b2"
      },
      "source": [
        "# load dataset\n",
        "pickle_in = open('df.pickle', 'rb')\n",
        "df = pickle.load(pickle_in)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username</th>\n",
              "      <th>User handle</th>\n",
              "      <th>Date of posting</th>\n",
              "      <th>Text</th>\n",
              "      <th>Retweet count</th>\n",
              "      <th>Like count</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Text (EPA)</th>\n",
              "      <th>Text (Model)</th>\n",
              "      <th>Word Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>@aliciakeys</td>\n",
              "      <td>Fri Feb 12 03:16:07 +0000 2021</td>\n",
              "      <td>The maestro! The musical magician! The one and...</td>\n",
              "      <td>170</td>\n",
              "      <td>1973</td>\n",
              "      <td>Artist</td>\n",
              "      <td>maestro musical magician believe knew played s...</td>\n",
              "      <td>the maestro! the musical magician! the one and...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>@aliciakeys</td>\n",
              "      <td>Wed Feb 10 21:31:09 +0000 2021</td>\n",
              "      <td>Your glow is about to be on 100,000!!! ✨As we ...</td>\n",
              "      <td>101</td>\n",
              "      <td>1171</td>\n",
              "      <td>Artist</td>\n",
              "      <td>glow 100,000 lead reminder love wait luminous ...</td>\n",
              "      <td>your glow is about to be on 100,000!!! as we l...</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>@aliciakeys</td>\n",
              "      <td>Wed Feb 10 01:32:56 +0000 2021</td>\n",
              "      <td>Woke up in such a good vibe.⁣ Gen was funky &amp;a...</td>\n",
              "      <td>267</td>\n",
              "      <td>3659</td>\n",
              "      <td>Artist</td>\n",
              "      <td>woke good vibe.⁣ funky fussy caught energy thi...</td>\n",
              "      <td>woke up in such a good vibe. gen was funky &amp;am...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>@aliciakeys</td>\n",
              "      <td>Mon Feb 08 01:41:28 +0000 2021</td>\n",
              "      <td>One of my favorite small businesses is @unionl...</td>\n",
              "      <td>144</td>\n",
              "      <td>816</td>\n",
              "      <td>Artist</td>\n",
              "      <td>favorite small businesses unionlosangeles repl...</td>\n",
              "      <td>one of my favorite small businesses is@unionlo...</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alicia Keys</td>\n",
              "      <td>@aliciakeys</td>\n",
              "      <td>Mon Feb 08 01:22:00 +0000 2021</td>\n",
              "      <td>Dreaming of performing live \\nfor you!!! ✨✨✨✨\\...</td>\n",
              "      <td>275</td>\n",
              "      <td>5028</td>\n",
              "      <td>Artist</td>\n",
              "      <td>dreaming performing live city come meet tonight</td>\n",
              "      <td>dreaming of performing live for you!!! what ci...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Username  ... Word Count\n",
              "0  Alicia Keys  ...         40\n",
              "1  Alicia Keys  ...         54\n",
              "3  Alicia Keys  ...         52\n",
              "4  Alicia Keys  ...         33\n",
              "5  Alicia Keys  ...         21\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k85Yni-2HEI2",
        "outputId": "d3713fe9-bd01-4998-ff44-7d8fc9eccc4e"
      },
      "source": [
        "names = sorted(list(df['Username'].value_counts().index))\n",
        "print(names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Alicia Keys', 'Anthony Joshua', 'Barack Obama', 'Bill Gates', \"Conan O'Brien\", 'Donald Trump', 'Dwayne Johnson', 'Elizabeth Warren', 'Ellen DeGeneres', 'Elon Musk', 'Emma Watson', 'Gordon Ramsay', 'Harry Styles.', 'Jeff Weiner', 'Joe Biden', 'John Cena', 'Kevin Durant', 'Kevin Hart', 'Kylie Jenner', 'Lady Gaga', 'LeBron James', 'Louis Tomlinson', 'Mariah Carey', 'Neil Patrick Harris', 'Oprah Winfrey', 'Pope Francis', 'Ronda Rousey', 'Tim Cook', 'Wiz Khalifa', 'daniel tosh', 'jimmy fallon']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ah2Apx9OkK4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53fcnjYMHEN6",
        "outputId": "68df176d-f5e8-48a5-a060-d0babbcdcff7"
      },
      "source": [
        "# create a list of all characters\n",
        " chars = sorted(list(set(''.join(tweets))))\n",
        " print('Number of characters: ',len(chars))\n",
        "\n",
        "# create a dictionary assigning each character to a number\n",
        " char_number= dict((c,i) for i,c in enumerate(chars))\n",
        "\n",
        "# create a dictionary assigning each number to a character\n",
        "\n",
        " number_char = dict((i,c) for i,c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of characters:  58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNtpPYRLHEQu",
        "outputId": "70be519d-2afe-4300-8d17-0978638872e0"
      },
      "source": [
        "\n",
        "\n",
        "# constants\n",
        "LENGTH = 50 # sequence length\n",
        "STEP = 1 \n",
        "\n",
        "# input\n",
        "sentences = []\n",
        "\n",
        "# output\n",
        "next_char = []\n",
        "\n",
        "# create sequences and their corresponding output \n",
        "for x in tweets:\n",
        "  for i in range(0, len(x)- LENGTH, STEP):\n",
        "    sentences.append(x[i:i+LENGTH])\n",
        "    next_char.append(x[i+LENGTH])\n",
        "\n",
        "\n",
        "print('Number of sequences: ',len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences:  46582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvz75vmHETv"
      },
      "source": [
        "# create input and output arrays\n",
        "x = np.zeros((len(sentences), LENGTH, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "# assign 1 for characters that are present in the char_number dictionary\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for j, character in enumerate(sentence):\n",
        "    x[i, j, char_number[character]] = 1\n",
        "  y[i, char_number[next_char[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR76YP1QHEWr",
        "outputId": "8bc7d3ab-0ffe-445b-89a8-bed1e305380a"
      },
      "source": [
        "# dimensions of x and y\n",
        "print('Dimensions of x: ',x.shape)\n",
        "print('Dimensions of y: ',y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions of x:  (46582, 50, 58)\n",
            "Dimensions of y:  (46582, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLAwL4AuHEZM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYHwbxgPLIw"
      },
      "source": [
        "## Modified LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVOTRMMGHEb7"
      },
      "source": [
        "# build LSTM model\n",
        "modified_model = Sequential()\n",
        "modified_model.add(LSTM(256, input_shape=(LENGTH, len(chars)), return_sequences=True))\n",
        "modified_model.add(Dropout(0.25))\n",
        "modified_model.add(LSTM(128, return_sequences=True))\n",
        "modified_model.add(Dropout(0.25))\n",
        "modified_model.add(LSTM(128))\n",
        "modified_model.add(Dropout(0.25))\n",
        "\n",
        "modified_model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "modified_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Hz6tPSHVQ2"
      },
      "source": [
        "# create a sample text with the model\n",
        "# temperature variable --> creativity, the higher, the more creative\n",
        "def create_sample(prediction, temperature = 1):\n",
        "  prediction = np.asarray(prediction).astype('float64')\n",
        "  prediction = np.log(prediction)/temperature\n",
        "  exp_preds = np.exp(prediction)\n",
        "  prediction = exp_preds/np.sum(exp_preds)\n",
        "  probability = np.random.multinomial(1,prediction, 1)\n",
        "  return np.argmax(probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADs2X92HVYg"
      },
      "source": [
        "# print text with generated sentences\n",
        "def print_text(epoch, _):\n",
        "  print()\n",
        "  print('Generating Text after Epoch ',epoch)\n",
        "\n",
        "  tweet = np.random.choice(tweets)\n",
        "  start_index = 0\n",
        "  for val in [  0.75]:\n",
        "    print('Value: ', val)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = tweet[start_index: start_index+LENGTH]\n",
        "    generated += sentence\n",
        "\n",
        "    print('Generated sentence: \"',sentence+'\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(110):\n",
        "      x_pred = np.zeros((1, LENGTH, len(chars)))\n",
        "      for j, character in enumerate(sentence):\n",
        "        x_pred[0, j, char_number[character]] = 1\n",
        "\n",
        "      prediction = modified_model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = create_sample(prediction, val)\n",
        "      next_char = number_char[next_index]\n",
        "\n",
        "      generated += next_char\n",
        "      sentence = sentence[1:] + next_char\n",
        "\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kO5wIyJHVbj",
        "outputId": "deac23e6-6df4-4feb-d0c2-4cf985cc6c78"
      },
      "source": [
        "# train model\n",
        "EPOCHS = 20\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=print_text)\n",
        "\n",
        "modified_model.fit(x, y, batch_size=128, epochs=EPOCHS, callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "364/364 [==============================] - 305s 825ms/step - loss: 3.2517\n",
            "\n",
            "Generating Text after Epoch  0\n",
            "Value:  0.75\n",
            "Generated sentence: \" i would be honored. \"\n",
            "i would be honored. la r oi ahleo n w a hluogaisuiseeosoersu oga  oaaraatoisab!iootdoiein ath @s  !  u h  eioavo ut )  htnrte!iytd\n",
            "Epoch 2/20\n",
            "364/364 [==============================] - 299s 820ms/step - loss: 3.1091\n",
            "\n",
            "Generating Text after Epoch  1\n",
            "Value:  0.75\n",
            "Generated sentence: \" boat buddies forever. haaaaaa. you guys killed it.\"\n",
            "boat buddies forever. haaaaaa. you guys killed it. ss yh s hftl!e rews #ll xs we thont toc ghs ( se @ an pud doto ad le afe mhy yisag ponl am te sang aticidh to\n",
            "Epoch 3/20\n",
            "364/364 [==============================] - 299s 820ms/step - loss: 2.7023\n",
            "\n",
            "Generating Text after Epoch  2\n",
            "Value:  0.75\n",
            "Generated sentence: \" its hashtags time! tell us a funny thing you heard\"\n",
            "its hashtags time! tell us a funny thing you heard and. sasgen eed #tale yol th nelr. anen the ad coe buw @felltond tolirs #fallenfane to los so thurs an thanp \n",
            "Epoch 4/20\n",
            "364/364 [==============================] - 298s 820ms/step - loss: 2.4756\n",
            "\n",
            "Generating Text after Epoch  3\n",
            "Value:  0.75\n",
            "Generated sentence: \" still not over this. she is just crushing right no\"\n",
            "still not over this. she is just crushing right not @fallonlonor this we meins i coule chhang dise on hor im than of the #ambaane #tathe couk! mouj the the @fal\n",
            "Epoch 5/20\n",
            "364/364 [==============================] - 298s 818ms/step - loss: 2.3151\n",
            "\n",
            "Generating Text after Epoch  4\n",
            "Value:  0.75\n",
            "Generated sentence: \" one of the best father/son life lessons ive ever h\"\n",
            "one of the best father/son life lessons ive ever home  #shewants and on ameuend a mumbeis endensy @fallontone thet ir fom lors berarons innrerperfass beder that\n",
            "Epoch 6/20\n",
            "364/364 [==============================] - 298s 817ms/step - loss: 2.2295\n",
            "\n",
            "Generating Text after Epoch  5\n",
            "Value:  0.75\n",
            "Generated sentence: \" here we go! #macysparade @nbc @macys \"\n",
            "here we go! #macysparade @nbc @macys t)oo,a_td,de;.0milpe,)idene )eu s  na k0.km us.i q uoat eed0yxo,sicyysiky c:ylss s, .ynefii.unaa iuaea .aoe)e,\n",
            "Epoch 7/20\n",
            "364/364 [==============================] - 298s 819ms/step - loss: 2.1636\n",
            "\n",
            "Generating Text after Epoch  6\n",
            "Value:  0.75\n",
            "Generated sentence: \" some kids wrote @chancetherapper some raps... shou\"\n",
            "some kids wrote @chancetherapper some raps... shound rontere domere gelk bu and me and then um wath @byforpangine. fras @jankielanmels wore in the enmerbowe iv \n",
            "Epoch 8/20\n",
            "364/364 [==============================] - 298s 819ms/step - loss: 2.0930\n",
            "\n",
            "Generating Text after Epoch  7\n",
            "Value:  0.75\n",
            "Generated sentence: \" couldnt happen to a better guy. congrats @harry_st\"\n",
            "couldnt happen to a better guy. congrats @harry_store! #fallontonight #farlontonight. plude theeks and @fallonmono a coming hite _ceasets! #fallontonight #fallo\n",
            "Epoch 9/20\n",
            "364/364 [==============================] - 298s 818ms/step - loss: 2.0593\n",
            "\n",
            "Generating Text after Epoch  8\n",
            "Value:  0.75\n",
            "Generated sentence: \" mad lib theater with @kenanthompson and @joemangan\"\n",
            "mad lib theater with @kenanthompson and @joemangang kuks and tighe mame song a me ouvs#s'ur togim fir a for and comand afe arout to night loke on the #fallonmon\n",
            "Epoch 10/20\n",
            "364/364 [==============================] - 299s 821ms/step - loss: 2.0338\n",
            "\n",
            "Generating Text after Epoch  9\n",
            "Value:  0.75\n",
            "Generated sentence: \" also - if you wanna see a real doc about a great r\"\n",
            "also - if you wanna see a real doc about a great rusicten intepthes you word funring luth and borgial fallonto itig sming our jide. parder)  and beally to marca\n",
            "Epoch 11/20\n",
            "364/364 [==============================] - 298s 819ms/step - loss: 1.9776\n",
            "\n",
            "Generating Text after Epoch  10\n",
            "Value:  0.75\n",
            "Generated sentence: \" live show tonight with @gwenstefani, @bensplatt an\"\n",
            "live show tonight with @gwenstefani, @bensplatt and and mustauss @alemanmer from @comlialinhell on could huthid word on weeks and me sot buve samitht! dustor. w\n",
            "Epoch 12/20\n",
            "364/364 [==============================] - 298s 817ms/step - loss: 1.9444\n",
            "\n",
            "Generating Text after Epoch  11\n",
            "Value:  0.75\n",
            "Generated sentence: \" news &amp; jokes for friday 12/4/20. #fallontonigh\"\n",
            "news &amp; jokes for friday 12/4/20. #fallontonight #fallonnono gome um birking with #damunni)  from @snoby on the show. i live to @cheshiletony and a mamedded \n",
            "Epoch 13/20\n",
            "364/364 [==============================] - 296s 814ms/step - loss: 1.9169\n",
            "\n",
            "Generating Text after Epoch  12\n",
            "Value:  0.75\n",
            "Generated sentence: \" today is the day!!! its available!! \"\n",
            "today is the day!!! its available!! .   e a . s  ! .eeie  ei e. d. .y) eeea\"iy  at  ,.    edi  !   r,!  - .?s!a, d us,as!os, y,,!      .,   r     \n",
            "Epoch 14/20\n",
            "364/364 [==============================] - 297s 816ms/step - loss: 1.8775\n",
            "\n",
            "Generating Text after Epoch  13\n",
            "Value:  0.75\n",
            "Generated sentence: \" thank you @nygovcuomo. please keep talking to us.\"\n",
            "thank you @nygovcuomo. please keep talking to us.l ao ow uta  f  t   de beon  uos, eeonk.r ao o e silbfnte su adu,as etneaorda a aeia s  rta   srteuf. eentn ed\n",
            "Epoch 15/20\n",
            "364/364 [==============================] - 299s 820ms/step - loss: 2.8304\n",
            "\n",
            "Generating Text after Epoch  14\n",
            "Value:  0.75\n",
            "Generated sentence: \" not what i was expecting @iamcardib  \"\n",
            "not what i was expecting @iamcardib  sil,t) ,a.el,. ea c) ae rlnisi.nsa,a!_,,  el?  saoel m,s,d -r)nw. )! , ,l,aii,e a lr r, r s oab e)r ,, em !s ,\n",
            "Epoch 16/20\n",
            "364/364 [==============================] - 298s 819ms/step - loss: 2.2351\n",
            "\n",
            "Generating Text after Epoch  15\n",
            "Value:  0.75\n",
            "Generated sentence: \" .@jbalvin talks about ending up on stage with beyo\"\n",
            ".@jbalvin talks about ending up on stage with beyoe hore our the s welln os the wot s and thank swe so rusicrfats #fallontonight #fallonmono tank a yey from the\n",
            "Epoch 17/20\n",
            "364/364 [==============================] - 298s 818ms/step - loss: 2.0878\n",
            "\n",
            "Generating Text after Epoch  16\n",
            "Value:  0.75\n",
            "Generated sentence: \" tonight on the show: @michaelstrahan and the @bell\"\n",
            "tonight on the show: @michaelstrahan and the @bellyfiyhere and the show! with #sfirytatafaoc @blthrasnot a and music from @dige ffom @berways museres xtsing a p\n",
            "Epoch 18/20\n",
            "364/364 [==============================] - 300s 823ms/step - loss: 2.0066\n",
            "\n",
            "Generating Text after Epoch  17\n",
            "Value:  0.75\n",
            "Generated sentence: \" thank you my brother!!! respectfully, dennis hope \"\n",
            "thank you my brother!!! respectfully, dennis hope for the show! #fallontonight #fallonmono peno on the show that wing the show!! thask you, rore toright and a c\n",
            "Epoch 19/20\n",
            "364/364 [==============================] - 297s 816ms/step - loss: 1.9530\n",
            "\n",
            "Generating Text after Epoch  18\n",
            "Value:  0.75\n",
            "Generated sentence: \" the tonight show: at home edition (@pharrell and @\"\n",
            "the tonight show: at home edition (@pharrell and @barentenfors! you pull exfradeitaral arine and are you thelk en heod tre minan rikesluns comith the same thit \n",
            "Epoch 20/20\n",
            "364/364 [==============================] - 304s 834ms/step - loss: 1.9203\n",
            "\n",
            "Generating Text after Epoch  19\n",
            "Value:  0.75\n",
            "Generated sentence: \" love for the army. #btsonfallon\"\n",
            "love for the army. #btsonfallon ose )  aui  !e   ce,.    aoe iieie,  , ..  o.ta  . yee   a.a.!y e ai  n- ey s e  o  i,i,daioaoe   sc  m!)-ba \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd965b2a950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y63szdiHVeY"
      },
      "source": [
        "# create text with a given sentence and diversity  value\n",
        "def generate_text(sentence, diversity):\n",
        "  sentence = sentence[0: LENGTH]\n",
        "  print('sentence: ',sentence)\n",
        "  print('diversity: ',diversity)\n",
        "\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  text_generated = ''\n",
        "  sys.stdout.write(generated)\n",
        "\n",
        "  for i in range(120):\n",
        "    x_pred = np.zeros((1, LENGTH, len(chars)))\n",
        "    for j, character in enumerate(sentence):\n",
        "      x_pred[0, j, char_number[character]] = 1\n",
        "    \n",
        "    prediction = modified_model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = create_sample(prediction, diversity)\n",
        "    next_char = number_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    text_generated += next_char  \n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "  print()\n",
        "  return text_generated\n",
        "\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfBrf7U5HVg_",
        "outputId": "0afbf2f2-d2db-4cab-a58a-1c8ff6cf046a"
      },
      "source": [
        "generated_texts = []\n",
        "# create sentences and add them to the generated_texts list\n",
        "\n",
        "for sample in random.sample(list(tweets), 30):\n",
        "  for diversity in [0.75]:\n",
        "    generated_texts.append(generate_text(sample, diversity))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence:  news &amp; jokes for friday 11/20/20. #fallontonig\n",
            "diversity:  0.75\n",
            "news &amp; jokes for friday 11/20/20. #fallontonight #fallonmono here on the show!!!!! that on becimetain he in wrisher scomen the the show this you hed in song: hith in \n",
            "\n",
            "sentence:  its hashtags time! use six words to describe the u\n",
            "diversity:  0.75\n",
            "its hashtags time! use six words to describe the ure is guit the same on the show!!! #to aldormeal in by and whass in youre by keringruxgiytume how @diythadvanthlots, con\n",
            "\n",
            "sentence:  tonight: @chancetherapper is here, talk with @thed\n",
            "diversity:  0.75\n",
            "tonight: @chancetherapper is here, talk with @thedaallisi. on in inm wimt fun. hame! in a well in the show!!?! that it suw the show! #andemallowfor stall you. you have do\n",
            "\n",
            "sentence:  me and paul rudd do a shot-for-shot remake of dead\n",
            "diversity:  0.75\n",
            "me and paul rudd do a shot-for-shot remake of deadone. and tug i sibe os the show! hour fyaw e pun me falpond chacken #gureachadsicenaten gimed and a prrome bround @deali\n",
            "\n",
            "sentence:  the tonight show: at home edition (@pharrell and @\n",
            "diversity:  0.75\n",
            "the tonight show: at home edition (@pharrell and @thenkigvergars, all tanight to spen tuts afdien did he and theer ut thear s of happ be hat waek somethat fam homile? nes\n",
            "\n",
            "sentence:  presenting... #fallonlore the doc, inspired by #fo\n",
            "diversity:  0.75\n",
            "presenting... #fallonlore the doc, inspired by #folntorfatestay. couls to showo!!! with @threcomrosters a bive the show!!! shaw see wall us a deald and thank you and than\n",
            "\n",
            "sentence:  if you buy @elvisduranshow s book you get a discou\n",
            "diversity:  0.75\n",
            "if you buy @elvisduranshow s book you get a discous. couw to it with #this,seald and tell your from  jeckraoletthanks! #fallontonight #fallonmono gon guy. could blowe #ul\n",
            "\n",
            "sentence:  guys! if youre out doing some holiday shopping tod\n",
            "diversity:  0.75\n",
            "guys! if youre out doing some holiday shopping toditht end cometing and it 10howing in prings ard the go #fallontonight #fallonmono the thenk sperion fyom @bindietblicobo\n",
            "\n",
            "sentence:  every friday leading up to black friday @dopequeen\n",
            "diversity:  0.75\n",
            "every friday leading up to black friday @dopequeencowstay whas it keint on wiit. you the show!. toel batings @thistfilly the show! #fallontonight #showsoov. @theildaminge\n",
            "\n",
            "sentence:  thank you for the question! we loved it. \n",
            "diversity:  0.75\n",
            "thank you for the question! we loved it. di i ri r s !y  eluys i isttnie,o .  iioiiioee ues d .i,ayrvye.in liiorewt  oe rtn s  cebds,ad)eeaaa i ms a .aa  eos!i!y\n",
            "\n",
            "sentence:  the tonight show: at home edition (michael shannon\n",
            "diversity:  0.75\n",
            "the tonight show: at home edition (michael shannoned with #thenatsendisterbapllonug)  #fallontonight #fallonmonight #fallonmono go talk you. in word youl and thay if bt h\n",
            "\n",
            "sentence:  bad bunny delivers tonight at midnight!! get ready\n",
            "diversity:  0.75\n",
            "bad bunny delivers tonight at midnight!! get ready theuw you ard helrer mabl you spirt new! mealen iv cimine (ulcaref. your. geary preekdic and tag it with #therest and s\n",
            "\n",
            "sentence:  fun show tonight: @howardstern is here to talk abo\n",
            "diversity:  0.75\n",
            "fun show tonight: @howardstern is here to talk abour the get and teg your scoptsfere. a beont bared is the chair of jov to @cheradas new the show! it with here benore sho\n",
            "\n",
            "sentence:  thanks again everyone who came out for the #macysd\n",
            "diversity:  0.75\n",
            "thanks again everyone who came out for the #macysdecats of ryeray talk we whay song and the show. steritht? wand a performance chorcers. with @jemonadeburtere @fallontoni\n",
            "\n",
            "sentence:  know your bro with @jonasbrothers!  #fallontonight\n",
            "diversity:  0.75\n",
            "know your bro with @jonasbrothers!  #fallontonight #fallonmono so hoct the cand of @amhyfallontonight #fallommono gonight #fallonmono gould to #restemenney and stonight t\n",
            "\n",
            "sentence:  icymi let me love you like a woman last night @lan\n",
            "diversity:  0.75\n",
            "icymi let me love you like a woman last night @lanena - wot it wan coniythaver eno hesting spew staen and a comate a cand het to ade le himelon erring. hecey. chenk won i\n",
            "\n",
            "sentence:  congrats, jungkook. im not mad, i promise. #btsonf\n",
            "diversity:  0.75\n",
            "congrats, jungkook. im not mad, i promise. #btsonfallon dis ging of @merin_allonders #gareelac of @jilla_gally @fallontonight #fallonmono do it with #barcobory) #fallonto\n",
            "\n",
            "sentence:  it's time for tonight show: at home edition hashta\n",
            "diversity:  0.75\n",
            "it's time for tonight show: at home edition hashtant (favonthanky the it with in a performanme fallonmine samey hirles monidgh. mot seise mornens! #radandonwitendon #fapl\n",
            "\n",
            "sentence:  veyetamins. vitamins added to eye drops. for peopl\n",
            "diversity:  0.75\n",
            "veyetamins. vitamins added to eye drops. for peopleeg #fallondonight say of @todithersepard) ##wordidatananleffeirly stome and bleme fan yor. @yherereciaky terish. and a \n",
            "\n",
            "sentence:  the tonight show: at home edition (@realhughjackma\n",
            "diversity:  0.75\n",
            "the tonight show: at home edition (@realhughjackmaret of @addarnebrows at - comight beard you gus. chenict #bbidkmottes come and thank you the shig!!!!! a funny  andantan\n",
            "\n",
            "sentence:  thank you @andy and @deadandcompany for the best 1\n",
            "diversity:  0.75\n",
            "thank you @andy and @deadandcompany for the best 1 nintt hime on wliss dowely by me on sula for the show!! thas is. peepy from @amliter lole tonight the chower jiver duk \n",
            "\n",
            "sentence:  fun show tonight - quentin tarantino breaks down h\n",
            "diversity:  0.75\n",
            "fun show tonight - quentin tarantino breaks down how to @parroonjiylar! and @bingeris frame #gallyoods #fallontonight #fallonpono go on to chicing sone that you - the sin\n",
            "\n",
            "sentence:  it was always burning. \n",
            "diversity:  0.75\n",
            "it was always burning. e.ti b e  ,e t\"n,  e esasiy,)aym!  d  o,,si.s,a ,i. .  ii!i,i.c umepa  si i ie ,e i o.!  em sso.e) s i  f vo,,,yal ic.aa\n",
            "\n",
            "sentence:  always doing something different. respect. \n",
            "diversity:  0.75\n",
            "always doing something different. respect. ,?y  oim ce  ieinte  nome. iiy, iiiee aa e m  st  et r o s . e.iaii eee)aeeiiiictaen yd.sr. iit ree  rcstiins,eacaeal!ae\n",
            "\n",
            "sentence:  it's hashtags time! take the title of a tv show an\n",
            "diversity:  0.75\n",
            "it's hashtags time! take the title of a tv show and the mreining and @gunygerollsweardeers full #sackersin_antt @andenctssbint #fallontonight #fallonmono ou mist and the \n",
            "\n",
            "sentence:  good morning italy!!! here we go!!! \n",
            "diversity:  0.75\n",
            "good morning italy!!! here we go!!! ee le iu u embgpa y er .ln.e onlo ls e    ye.!ec  ioi,e eyi e! e i   ),cey ybn  e ei!s eeoe  u,.a .oeroe      ! e ipeai \n",
            "\n",
            "sentence:  im so excited about the show tonight. its a very d\n",
            "diversity:  0.75\n",
            "im so excited about the show tonight. its a very diig. deithringenitien 113 show- to scer now!! sould to spape - weir mis sting. and a wand he we ply. in. think you sumic\n",
            "\n",
            "sentence:  tonight: @trevornoah, @sebastiancomedy and magic f\n",
            "diversity:  0.75\n",
            "tonight: @trevornoah, @sebastiancomedy and magic from @5uagycrally in a fan score on thie gay mering, and haint to and a roupd all.dael wering and the katk of the the sho\n",
            "\n",
            "sentence:  the tonight show: at home edition (@officialsting \n",
            "diversity:  0.75\n",
            "the tonight show: at home edition (@officialsting from @resbistatrigeonds (thither song and wut an mor skreend tonight! @wheckingeldewige effor the show!!?!?. the whacs i\n",
            "\n",
            "sentence:  that was very cool. we heard you!thank you to all \n",
            "diversity:  0.75\n",
            "that was very cool. we heard you!thank you to all o fallont the chounth story in somethay looks hood it fanping to chanky the paredtay and the stow! thank you gis to my p\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJj57MS0HVmv"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTwhcOnZLtwP"
      },
      "source": [
        "## Save Generated Text as Pickle File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJOqqK9tHgBP"
      },
      "source": [
        "# export generated text\n",
        "text_pickle_out = open(\"fallon_text_generation_modified.pickle\", 'wb')\n",
        "pickle.dump(generated_texts, text_pickle_out)\n",
        "text_pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzBV944kIdNr"
      },
      "source": [
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jumXePWg9ux-"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwKptfX4OecD"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yByBqbCCUXrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}